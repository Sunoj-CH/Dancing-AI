{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135f995-7d9c-4697-be7c-f449c03b3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create UDP socket\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "server_address = ('127.0.0.1', 5050)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip frame to mirror image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Original feed for the left side\n",
    "    original = frame.copy()\n",
    "\n",
    "    # Black image for the skeleton side\n",
    "    skeleton = np.zeros_like(frame)\n",
    "\n",
    "    # Convert to RGB\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        key_indices = [0, 11, 12, 13, 14, 23, 24]  # Nose, shoulders, elbows, hips\n",
    "\n",
    "        for idx in key_indices:\n",
    "            lm = landmarks[idx]\n",
    "            data[str(idx)] = {'x': lm.x, 'y': lm.y, 'z': lm.z}\n",
    "            print(f\"Joint {idx}: x={lm.x:.2f}, y={lm.y:.2f}, z={lm.z:.2f}\")\n",
    "\n",
    "        # Send JSON to Unity\n",
    "        message = json.dumps(data).encode()\n",
    "        sock.sendto(message, server_address)\n",
    "        print(\"Data sent to Unity ğŸš€\")\n",
    "\n",
    "        # Draw pose landmarks on the black image\n",
    "        mp_drawing.draw_landmarks(\n",
    "            skeleton,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "        )\n",
    "    else:\n",
    "        print(\"âŒ Pose not detected\")\n",
    "\n",
    "    # Combine both views side-by-side\n",
    "    combined = np.hstack((original, skeleton))\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"You (Left) vs Skeleton (Right)\", combined)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661fc95-7b8c-4433-908c-88696809d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Load the anime face image (must be in same folder as this notebook)\n",
    "face_img = cv2.imread('/media/snow/Dracaryz/dancingai/.ipynb_checkpoints/anime_face-checkpoint.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Check if image is loaded\n",
    "if face_img is None:\n",
    "    print(\"âŒ Error: Could not load 'anime_face.png'. Make sure it's in the same folder.\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Resize face image\n",
    "face_img = cv2.resize(face_img, (100, 100))\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    # Left view: original webcam\n",
    "    left = frame.copy()\n",
    "\n",
    "    # Right view: black background\n",
    "    right = np.zeros_like(frame)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        # Draw skeleton on right canvas\n",
    "        mp_drawing.draw_landmarks(\n",
    "            right,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=4, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=4)\n",
    "        )\n",
    "\n",
    "        # Get the nose landmark (landmark index 0)\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        h, w, _ = right.shape\n",
    "        nose = landmarks[0]\n",
    "        cx, cy = int(nose.x * w), int(nose.y * h)\n",
    "\n",
    "        # Resize face image (already 100x100)\n",
    "        face_h, face_w, _ = face_img.shape\n",
    "        x1 = cx - face_w // 2\n",
    "        y1 = cy - face_h // 2\n",
    "        x2 = x1 + face_w\n",
    "        y2 = y1 + face_h\n",
    "\n",
    "        # Make sure face overlay is inside bounds\n",
    "        if x1 >= 0 and y1 >= 0 and x2 <= w and y2 <= h:\n",
    "            roi = right[y1:y2, x1:x2]\n",
    "            face_rgb = face_img[:, :, :3]\n",
    "            face_alpha = face_img[:, :, 3] / 255.0\n",
    "\n",
    "            # Alpha blending face image over black background\n",
    "            for c in range(3):\n",
    "                roi[:, :, c] = roi[:, :, c] * (1 - face_alpha) + face_rgb[:, :, c] * face_alpha\n",
    "\n",
    "            right[y1:y2, x1:x2] = roi\n",
    "\n",
    "    # Combine left and right views\n",
    "    combined = np.hstack((left, right))\n",
    "\n",
    "    # Show side-by-side view\n",
    "    cv2.imshow(\"ğŸ§ You (Left) | ğŸ Anime Twin (Right)\", combined)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f6ef7-3d42-4f95-a06e-90ba082a24a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Load your full anime body image (with transparency)\n",
    "anime_img = cv2.imread('anime_body.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "if anime_img is None:\n",
    "    print(\"âŒ Could not load 'anime_body.png'. Make sure itâ€™s in the same folder.\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Resize your anime body image\n",
    "anime_img = cv2.resize(anime_img, (200, 300))  # You can change size here\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    # Left = original webcam\n",
    "    left = frame.copy()\n",
    "\n",
    "    # Right = empty black canvas\n",
    "    right = np.zeros_like(frame)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        h, w, _ = right.shape\n",
    "\n",
    "        # Use hip center to place anime body\n",
    "        left_hip = landmarks[23]\n",
    "        right_hip = landmarks[24]\n",
    "\n",
    "        # Average of left and right hip\n",
    "        cx = int(((left_hip.x + right_hip.x) / 2) * w)\n",
    "        cy = int(((left_hip.y + right_hip.y) / 2) * h)\n",
    "\n",
    "        # Overlay anime image at hip center\n",
    "        img_h, img_w, _ = anime_img.shape\n",
    "        x1 = cx - img_w // 2\n",
    "        y1 = cy - img_h // 2\n",
    "        x2 = x1 + img_w\n",
    "        y2 = y1 + img_h\n",
    "\n",
    "        if x1 >= 0 and y1 >= 0 and x2 <= w and y2 <= h:\n",
    "            roi = right[y1:y2, x1:x2]\n",
    "            char_rgb = anime_img[:, :, :3]\n",
    "            char_alpha = anime_img[:, :, 3] / 255.0\n",
    "\n",
    "            for c in range(3):\n",
    "                roi[:, :, c] = roi[:, :, c] * (1 - char_alpha) + char_rgb[:, :, c] * char_alpha\n",
    "\n",
    "            right[y1:y2, x1:x2] = roi\n",
    "\n",
    "    # Combine both views\n",
    "    combined = np.hstack((left, right))\n",
    "    cv2.imshow(\"You (Left) | Anime Avatar (Right)\", combined)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a1a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siamrpn_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
